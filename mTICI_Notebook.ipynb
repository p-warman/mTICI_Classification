{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mTICI Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSGdW-Z-bLtE",
        "outputId": "ea4784d4-8830-4b4b-98c5-a1202a543617"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weny2lEDchuB"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf.random.set_seed(1234)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eqJ0kZgbPH4",
        "outputId": "5c7f3db0-01ef-48ac-9527-492e8e12bdbc"
      },
      "source": [
        "DATASET_SIZE = 234\n",
        "data_dir_ap = '/content/gdrive/MyDrive/compound_img2/AP/'\n",
        "data_dir_L = '/content/gdrive/MyDrive/compound_img2/L/'\n",
        "\n",
        "\n",
        "ap_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_ap,\n",
        "  seed=42)\n",
        "\n",
        "\n",
        "L_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_L,\n",
        "  seed=42)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 234 files belonging to 2 classes.\n",
            "Found 234 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-nlA5PFdY0M"
      },
      "source": [
        "size = (150, 150)\n",
        "ap_ds = ap_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "L_ds = L_ds.map(lambda x, y: (tf.image.resize(x, size), y))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3oVErxvbnNW",
        "outputId": "097c1eb5-b753-4a54-9503-00de4f67477c"
      },
      "source": [
        "x_ap = np.empty([1, 150, 150, 3])\n",
        "y_ap = []\n",
        "for x,y in ap_ds:\n",
        "  x_ap = np.concatenate((x_ap, x), axis=0)\n",
        "  y_ap = np.concatenate([y_ap, y], axis=0)\n",
        "\n",
        "x_ap = x_ap[1:, :,:,:]\n",
        "\n",
        "x_L = np.empty([1, 150, 150, 3])\n",
        "y_L = []\n",
        "for x,y in L_ds:\n",
        "  x_L = np.concatenate((x_L, x), axis=0)\n",
        "  y_L = np.concatenate([y_L, y], axis=0)\n",
        "\n",
        "x_L = x_L[1:, :,:,:]\n",
        "\n",
        "print(x_ap.shape)\n",
        "print(x_L.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(234, 150, 150, 3)\n",
            "(234, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiPWXNcNxI6D",
        "outputId": "91fceb1e-247f-42e1-e1ec-a4d546c15aed"
      },
      "source": [
        "#Ensure that the images are ordered the same way between the AP and L splits\n",
        "print(y_L - y_ap)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ECMCEN2cgKI",
        "outputId": "30448c20-e248-4fa9-f498-da0757fd2f35"
      },
      "source": [
        "# Load weights pre-trained on ImageNet.\n",
        "# Do not include the ImageNet classifier at the top.\n",
        "\n",
        "base_model_ap = keras.applications.Xception(\n",
        "    weights=\"imagenet\",  \n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False,\n",
        ")  \n",
        "\n",
        "base_model_L = keras.applications.Xception(\n",
        "    weights=\"imagenet\",  \n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False,\n",
        ") "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZuJCQLEizWh"
      },
      "source": [
        "data_augmentation_ap = keras.Sequential(\n",
        "    [\n",
        "        layers .experimental.preprocessing.RandomFlip(\"horizontal\"), #L -> R flip\n",
        "        layers.experimental.preprocessing.RandomRotation(0.05),\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_augmentation_L = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"), #L -> R flip\n",
        "        layers.experimental.preprocessing.RandomRotation(0.05),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyyNPOY-eimh",
        "outputId": "ddfedf1f-73bb-4772-a913-edc6b1f958d9"
      },
      "source": [
        "accscores = []\n",
        "aucscores = []\n",
        "raw_preds = []\n",
        "gts = []\n",
        "\n",
        "for kfold, (train, test) in enumerate(KFold(n_splits=5, shuffle=True).split(x_ap, y_ap)):\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  base_model_ap.trainable = False\n",
        "  base_model_ap._name=\"AP-View-Model\"\n",
        "\n",
        "  inputs_ap = keras.Input(shape=(150, 150, 3) ,name= \"ap_input\")\n",
        "  \n",
        "  augmented_ap = data_augmentation_ap(inputs_ap)  \n",
        "\n",
        "  norm_layer_ap = keras.layers.experimental.preprocessing.Normalization()\n",
        "  mean = np.array([127.5] * 3)\n",
        "  var = mean ** 2\n",
        "  augmented_ap = norm_layer_ap(augmented_ap)\n",
        "  norm_layer_ap.set_weights([mean, var])\n",
        "\n",
        "  augmented_ap = base_model_ap(augmented_ap, training=False)\n",
        "\n",
        "  augmented_ap = keras.layers.GlobalAveragePooling2D()(augmented_ap)\n",
        "  augmented_ap = keras.layers.Dropout(0.2)(augmented_ap)  # Regularize with dropout\n",
        "  output_ap = keras.layers.Dense(1, activation='sigmoid')(augmented_ap)\n",
        "\n",
        "  model_ap = keras.Model(inputs_ap, output_ap)\n",
        "  #-----------Model is now defined, moving on to training---------\n",
        "\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "  model_ap.compile(\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.AUC()],\n",
        "  )\n",
        "\n",
        "  epochs = 200\n",
        "\n",
        "  #First fit with frozen weights\n",
        "  model_ap.fit(x_ap[train], y=y_ap[train], epochs=epochs, callbacks=[callback], validation_split=0.2)\n",
        "\n",
        "  base_model_ap.trainable = True\n",
        "\n",
        "  model_ap.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.AUC()],\n",
        "  ) \n",
        "\n",
        "  epochs = 40\n",
        "\n",
        "  #Second fit\n",
        "  model_ap.fit(x_ap[train], y=y_ap[train], epochs=epochs, callbacks=[callback], validation_split=0.2)\n",
        "\n",
        "  #Evaluate\n",
        "  predictions = model_ap.predict(x_ap[test])\n",
        "  raw_preds.append(predictions)\n",
        "  gts.append(y_ap[test])\n",
        "  scores = model_ap.evaluate(x_ap[test], y=y_ap[test])\n",
        "\n",
        "\n",
        "  print(\"%s: %.2f%%\" % (model_ap.metrics_names[0], scores[0]*100))\n",
        "  accscores.append(scores[1] * 100)\n",
        "  aucscores.append(scores[2])\n",
        " \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accscores), np.std(accscores)))\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(aucscores), np.std(aucscores)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:5017: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 5s 313ms/step - loss: 1.4516 - binary_accuracy: 0.5638 - auc: 0.5207 - val_loss: 0.4321 - val_binary_accuracy: 0.8158 - val_auc: 0.8936\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.2616 - binary_accuracy: 0.9060 - auc: 0.9753 - val_loss: 0.4579 - val_binary_accuracy: 0.8947 - val_auc: 0.9188\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0619 - binary_accuracy: 0.9799 - auc: 0.9986 - val_loss: 0.6518 - val_binary_accuracy: 0.8947 - val_auc: 0.9272\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0129 - binary_accuracy: 0.9933 - auc: 1.0000 - val_loss: 0.7668 - val_binary_accuracy: 0.8947 - val_auc: 0.9300\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0176 - binary_accuracy: 0.9933 - auc: 1.0000 - val_loss: 0.8017 - val_binary_accuracy: 0.8947 - val_auc: 0.9300\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.0148 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7909 - val_binary_accuracy: 0.8947 - val_auc: 0.9300\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0021 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7860 - val_binary_accuracy: 0.8947 - val_auc: 0.9300\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 9.8078e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7871 - val_binary_accuracy: 0.9211 - val_auc: 0.9300\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0020 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7908 - val_binary_accuracy: 0.9211 - val_auc: 0.9314\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7935 - val_binary_accuracy: 0.9211 - val_auc: 0.9314\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0072 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.8029 - val_binary_accuracy: 0.9211 - val_auc: 0.9314\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 7s 481ms/step - loss: 0.0064 - binary_accuracy: 0.9933 - auc_1: 1.0000 - val_loss: 0.9402 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9300\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0102 - binary_accuracy: 0.9933 - auc_1: 1.0000 - val_loss: 0.8799 - val_binary_accuracy: 0.9211 - val_auc_1: 0.9258\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 301ms/step - loss: 0.0075 - binary_accuracy: 0.9933 - auc_1: 1.0000 - val_loss: 0.8153 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9272\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0148 - binary_accuracy: 0.9866 - auc_1: 1.0000 - val_loss: 0.8425 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9356\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbd18ea5680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3596 - binary_accuracy: 0.9362 - auc_1: 0.9728\n",
            "loss: 35.96%\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 4s 287ms/step - loss: 0.8864 - binary_accuracy: 0.6309 - auc: 0.7001 - val_loss: 0.4472 - val_binary_accuracy: 0.8947 - val_auc: 0.9181\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.1118 - binary_accuracy: 0.9530 - auc: 0.9919 - val_loss: 0.5713 - val_binary_accuracy: 0.9211 - val_auc: 0.9278\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0347 - binary_accuracy: 0.9933 - auc: 1.0000 - val_loss: 0.7170 - val_binary_accuracy: 0.8947 - val_auc: 0.9250\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0027 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.8908 - val_binary_accuracy: 0.8947 - val_auc: 0.9361\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0094 - binary_accuracy: 0.9933 - auc: 1.0000 - val_loss: 0.9918 - val_binary_accuracy: 0.8947 - val_auc: 0.9361\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0042 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.0534 - val_binary_accuracy: 0.8947 - val_auc: 0.9389\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0064 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.0917 - val_binary_accuracy: 0.8947 - val_auc: 0.9389\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 7s 492ms/step - loss: 0.0031 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.9212 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9097\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 2.4867e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.0723 - val_binary_accuracy: 0.8684 - val_auc_1: 0.9306\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 6.0298e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.0525 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9319\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 7.6468e-05 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.0406 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9319\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 9.8082e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.3123 - val_binary_accuracy: 0.8684 - val_auc_1: 0.9139\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0028 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.1510 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9306\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 8.4367e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.0637 - val_binary_accuracy: 0.8684 - val_auc_1: 0.9083\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1730 - binary_accuracy: 0.9787 - auc_1: 0.9737\n",
            "loss: 17.30%\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 4s 309ms/step - loss: 0.7659 - binary_accuracy: 0.7181 - auc: 0.7962 - val_loss: 0.5773 - val_binary_accuracy: 0.8158 - val_auc: 0.9083\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.1255 - binary_accuracy: 0.9597 - auc: 0.9855 - val_loss: 0.4432 - val_binary_accuracy: 0.8947 - val_auc: 0.9319\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0452 - binary_accuracy: 0.9866 - auc: 0.9994 - val_loss: 0.5349 - val_binary_accuracy: 0.8947 - val_auc: 0.9278\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0076 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6267 - val_binary_accuracy: 0.8947 - val_auc: 0.9319\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0030 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6794 - val_binary_accuracy: 0.8947 - val_auc: 0.9306\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0016 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7228 - val_binary_accuracy: 0.8684 - val_auc: 0.9319\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 6.3194e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7537 - val_binary_accuracy: 0.8684 - val_auc: 0.9319\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0017 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7738 - val_binary_accuracy: 0.8684 - val_auc: 0.9306\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 4.3192e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7857 - val_binary_accuracy: 0.8684 - val_auc: 0.9319\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0088 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7628 - val_binary_accuracy: 0.8684 - val_auc: 0.9319\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7323 - val_binary_accuracy: 0.8947 - val_auc: 0.9333\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 3.5171e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7190 - val_binary_accuracy: 0.8947 - val_auc: 0.9333\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7204 - val_binary_accuracy: 0.8947 - val_auc: 0.9333\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 6.7898e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7259 - val_binary_accuracy: 0.8947 - val_auc: 0.9333\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0023 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7243 - val_binary_accuracy: 0.8947 - val_auc: 0.9333\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 7s 497ms/step - loss: 6.0053e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.6639 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9306\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.0016 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.7933 - val_binary_accuracy: 0.8684 - val_auc_1: 0.9361\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 0.0098 - binary_accuracy: 0.9933 - auc_1: 1.0000 - val_loss: 1.1851 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9181\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.0052 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.9043 - val_binary_accuracy: 0.8684 - val_auc_1: 0.9361\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5248 - binary_accuracy: 0.9787 - auc_1: 0.9762\n",
            "loss: 52.48%\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 4s 295ms/step - loss: 1.9730 - binary_accuracy: 0.4899 - auc: 0.4235 - val_loss: 0.5433 - val_binary_accuracy: 0.8158 - val_auc: 0.8421\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.1700 - binary_accuracy: 0.9463 - auc: 0.9807 - val_loss: 1.1018 - val_binary_accuracy: 0.8421 - val_auc: 0.9030\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0610 - binary_accuracy: 0.9732 - auc: 1.0000 - val_loss: 1.1388 - val_binary_accuracy: 0.8684 - val_auc: 0.8837\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0089 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.0312 - val_binary_accuracy: 0.8684 - val_auc: 0.9003\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0044 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.9774 - val_binary_accuracy: 0.8684 - val_auc: 0.9224\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.0036 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.9941 - val_binary_accuracy: 0.8947 - val_auc: 0.9224\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0022 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.0219 - val_binary_accuracy: 0.8947 - val_auc: 0.9224\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0123 - binary_accuracy: 0.9933 - auc: 1.0000 - val_loss: 1.0634 - val_binary_accuracy: 0.8947 - val_auc: 0.9003\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 8.0462e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.1641 - val_binary_accuracy: 0.8684 - val_auc: 0.8781\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0030 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.2092 - val_binary_accuracy: 0.8684 - val_auc: 0.8781\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0014 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.2357 - val_binary_accuracy: 0.8684 - val_auc: 0.8781\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.2481 - val_binary_accuracy: 0.8684 - val_auc: 0.8781\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 6s 478ms/step - loss: 7.2354e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.3152 - val_binary_accuracy: 0.8684 - val_auc_1: 0.9100\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 2.2350e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.4299 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8947\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 286ms/step - loss: 6.6601e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.1381 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9363\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0044 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.2903 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9100\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 1s 287ms/step - loss: 1.2164e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.8867 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8947\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0223 - binary_accuracy: 0.9933 - auc_1: 1.0000 - val_loss: 1.6344 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8947\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0239 - binary_accuracy: 0.9933 - auc_1: 0.9998 - val_loss: 1.0648 - val_binary_accuracy: 0.8684 - val_auc_1: 0.9266\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 1.1195e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.3019 - val_binary_accuracy: 0.8947 - val_auc_1: 0.8837\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 4.8159e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.4902 - val_binary_accuracy: 0.8947 - val_auc_1: 0.8947\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 1.2754e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.6023 - val_binary_accuracy: 0.8947 - val_auc_1: 0.8947\n",
            "Epoch 11/40\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0026 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.6042 - val_binary_accuracy: 0.8947 - val_auc_1: 0.8947\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0594 - binary_accuracy: 0.9787 - auc_1: 1.0000\n",
            "loss: 5.94%\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 4s 296ms/step - loss: 0.3386 - binary_accuracy: 0.8600 - auc: 0.9363 - val_loss: 0.7781 - val_binary_accuracy: 0.8421 - val_auc: 0.8992\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0428 - binary_accuracy: 0.9800 - auc: 0.9993 - val_loss: 0.7723 - val_binary_accuracy: 0.8421 - val_auc: 0.9076\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0098 - binary_accuracy: 0.9933 - auc: 1.0000 - val_loss: 0.9048 - val_binary_accuracy: 0.8684 - val_auc: 0.8950\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0040 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.0689 - val_binary_accuracy: 0.8421 - val_auc: 0.9118\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0034 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.2099 - val_binary_accuracy: 0.8684 - val_auc: 0.9118\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 7.4917e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.3111 - val_binary_accuracy: 0.8684 - val_auc: 0.8908\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 1.2174e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.3755 - val_binary_accuracy: 0.8684 - val_auc: 0.8908\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 8.8461e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.4076 - val_binary_accuracy: 0.8684 - val_auc: 0.8908\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0107 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.3502 - val_binary_accuracy: 0.8684 - val_auc: 0.8908\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.0047 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.3174 - val_binary_accuracy: 0.8421 - val_auc: 0.8908\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 7s 530ms/step - loss: 0.0147 - binary_accuracy: 0.9933 - auc_1: 1.0000 - val_loss: 1.5151 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8992\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 292ms/step - loss: 0.0035 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.0760 - val_binary_accuracy: 0.8684 - val_auc_1: 0.9076\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 292ms/step - loss: 0.0012 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 0.9682 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8894\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 2s 311ms/step - loss: 0.0044 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.0020 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8936\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 1s 292ms/step - loss: 0.0041 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 1.2893 - val_binary_accuracy: 0.8421 - val_auc_1: 0.9146\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 1s 291ms/step - loss: 0.0107 - binary_accuracy: 0.9933 - auc_1: 1.0000 - val_loss: 1.3141 - val_binary_accuracy: 0.8421 - val_auc_1: 0.9146\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0212 - binary_accuracy: 0.9783 - auc_1: 1.0000\n",
            "loss: 2.12%\n",
            "97.01% (+/- 1.70%)\n",
            "0.98% (+/- 0.01%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKFpxtzCfbyp"
      },
      "source": [
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]\n",
        "\n",
        "raw_preds_ap = flatten(flatten(raw_preds))\n",
        "gts_ap = flatten(gts)\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI6j3wM-lqzk",
        "outputId": "0dd37fa8-0369-4e98-8d99-ad0c0e00f1f8"
      },
      "source": [
        "accscores = []\n",
        "aucscores = []\n",
        "raw_preds = []\n",
        "gts = []\n",
        "\n",
        "for kfold, (train, test) in enumerate(KFold(n_splits=5, shuffle=True).split(x_L, y_L)):\n",
        "  tf.keras.backend.clear_session()\n",
        "  \n",
        "  base_model_L.trainable = False\n",
        "  base_model_L._name=\"L-Model\"\n",
        "\n",
        "  inputs_L = keras.Input(shape=(150, 150, 3), name=\"L_input\")\n",
        "  augmented_L = data_augmentation_L(inputs_L)  \n",
        "\n",
        "  norm_layer_L = keras.layers.experimental.preprocessing.Normalization()\n",
        "  mean = np.array([127.5] * 3)\n",
        "  var = mean ** 2\n",
        "  augmented_L = norm_layer_L(augmented_L)\n",
        "  norm_layer_L.set_weights([mean, var])\n",
        "  augmented_L = base_model_L(augmented_L, training=False)\n",
        "\n",
        "\n",
        "  augmented_L = keras.layers.GlobalAveragePooling2D()(augmented_L)\n",
        "  augmented_L = keras.layers.Dropout(0.2)(augmented_L)  # Regularize with dropout\n",
        "  output_L = keras.layers.Dense(1, activation='sigmoid')(augmented_L)\n",
        "  model_L = keras.Model(inputs_L, output_L)\n",
        "\n",
        "  #-----------Model is now defined, moving on to training---------\n",
        "\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "  model_L.compile(\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.AUC()],\n",
        "  )\n",
        "\n",
        "  epochs = 200\n",
        "\n",
        "  #First fit with frozen weights\n",
        "  model_L.fit(x_L[train], y=y_L[train], epochs=epochs, callbacks=[callback], validation_split=0.2)\n",
        "\n",
        "  base_model_L.trainable = True\n",
        "\n",
        "  model_L.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "      loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.AUC()],\n",
        "  )\n",
        "\n",
        "  epochs = 40\n",
        "\n",
        "  #Second fit\n",
        "  model_L.fit(x_L[train], y=y_L[train], epochs=epochs, callbacks=[callback], validation_split=0.2)\n",
        "\n",
        "  #Evaluate\n",
        "  predictions = model_L.predict(x_L[test])\n",
        "  raw_preds.append(predictions)\n",
        "  gts.append(y_L[test])\n",
        "  scores = model_L.evaluate(x_L[test], y=y_L[test])\n",
        "\n",
        "\n",
        "  print(\"%s: %.2f%%\" % (model_L.metrics_names[0], scores[0]*100))\n",
        "  accscores.append(scores[1] * 100)\n",
        "  aucscores.append(scores[2])\n",
        " \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accscores), np.std(accscores)))\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(aucscores), np.std(aucscores)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:5017: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 4s 289ms/step - loss: 0.6763 - binary_accuracy: 0.5772 - auc_10: 0.5931 - val_loss: 0.6902 - val_binary_accuracy: 0.6842 - val_auc_10: 0.6750\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.5970 - binary_accuracy: 0.6510 - auc_10: 0.7517 - val_loss: 0.7155 - val_binary_accuracy: 0.6842 - val_auc_10: 0.6847\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.5628 - binary_accuracy: 0.6980 - auc_10: 0.7801 - val_loss: 0.6553 - val_binary_accuracy: 0.6579 - val_auc_10: 0.7153\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.5181 - binary_accuracy: 0.7987 - auc_10: 0.8406 - val_loss: 0.6431 - val_binary_accuracy: 0.7105 - val_auc_10: 0.7375\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.4950 - binary_accuracy: 0.7852 - auc_10: 0.8527 - val_loss: 0.6409 - val_binary_accuracy: 0.6842 - val_auc_10: 0.7375\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.4578 - binary_accuracy: 0.8188 - auc_10: 0.8868 - val_loss: 0.6485 - val_binary_accuracy: 0.7105 - val_auc_10: 0.7403\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.4580 - binary_accuracy: 0.7785 - auc_10: 0.8707 - val_loss: 0.6382 - val_binary_accuracy: 0.6842 - val_auc_10: 0.7556\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.4204 - binary_accuracy: 0.8255 - auc_10: 0.9100 - val_loss: 0.6308 - val_binary_accuracy: 0.7105 - val_auc_10: 0.7722\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.4646 - binary_accuracy: 0.7919 - auc_10: 0.8650 - val_loss: 0.6396 - val_binary_accuracy: 0.6842 - val_auc_10: 0.7736\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.4235 - binary_accuracy: 0.8322 - auc_10: 0.8986 - val_loss: 0.6365 - val_binary_accuracy: 0.7105 - val_auc_10: 0.7792\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.4038 - binary_accuracy: 0.8188 - auc_10: 0.9094 - val_loss: 0.6302 - val_binary_accuracy: 0.7105 - val_auc_10: 0.7792\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.4080 - binary_accuracy: 0.8322 - auc_10: 0.9059 - val_loss: 0.6274 - val_binary_accuracy: 0.7105 - val_auc_10: 0.7819\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.4000 - binary_accuracy: 0.8255 - auc_10: 0.9053 - val_loss: 0.6375 - val_binary_accuracy: 0.7105 - val_auc_10: 0.7778\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.4090 - binary_accuracy: 0.8322 - auc_10: 0.9022 - val_loss: 0.6231 - val_binary_accuracy: 0.7368 - val_auc_10: 0.7903\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.3376 - binary_accuracy: 0.8792 - auc_10: 0.9500 - val_loss: 0.6297 - val_binary_accuracy: 0.7105 - val_auc_10: 0.7847\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.3736 - binary_accuracy: 0.8456 - auc_10: 0.9241 - val_loss: 0.6318 - val_binary_accuracy: 0.7368 - val_auc_10: 0.7861\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.3909 - binary_accuracy: 0.8456 - auc_10: 0.9019 - val_loss: 0.6200 - val_binary_accuracy: 0.7368 - val_auc_10: 0.7958\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.3369 - binary_accuracy: 0.8456 - auc_10: 0.9438 - val_loss: 0.6161 - val_binary_accuracy: 0.7895 - val_auc_10: 0.8028\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.3632 - binary_accuracy: 0.8322 - auc_10: 0.9240 - val_loss: 0.6163 - val_binary_accuracy: 0.7895 - val_auc_10: 0.8056\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.3546 - binary_accuracy: 0.8523 - auc_10: 0.9336 - val_loss: 0.6142 - val_binary_accuracy: 0.7632 - val_auc_10: 0.8056\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.3513 - binary_accuracy: 0.8591 - auc_10: 0.9336 - val_loss: 0.6135 - val_binary_accuracy: 0.7368 - val_auc_10: 0.8097\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 7s 472ms/step - loss: 0.3034 - binary_accuracy: 0.8859 - auc_11: 0.9558 - val_loss: 0.5912 - val_binary_accuracy: 0.7368 - val_auc_11: 0.8222\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.2974 - binary_accuracy: 0.8993 - auc_11: 0.9447 - val_loss: 0.5831 - val_binary_accuracy: 0.7895 - val_auc_11: 0.8375\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.2521 - binary_accuracy: 0.8725 - auc_11: 0.9619 - val_loss: 0.5852 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8597\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.2116 - binary_accuracy: 0.8993 - auc_11: 0.9764 - val_loss: 0.6046 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8653\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.1876 - binary_accuracy: 0.9262 - auc_11: 0.9808 - val_loss: 0.5881 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8694\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.1667 - binary_accuracy: 0.9329 - auc_11: 0.9827 - val_loss: 0.5904 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8722\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1466 - binary_accuracy: 0.9329 - auc_11: 0.9894 - val_loss: 0.5867 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8819\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1074 - binary_accuracy: 0.9664 - auc_11: 0.9958 - val_loss: 0.5891 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8889\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1351 - binary_accuracy: 0.9329 - auc_11: 0.9905 - val_loss: 0.6049 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8972\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.1051 - binary_accuracy: 0.9597 - auc_11: 0.9952 - val_loss: 0.5936 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8931\n",
            "Epoch 11/40\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0791 - binary_accuracy: 0.9799 - auc_11: 0.9990 - val_loss: 0.6182 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8986\n",
            "Epoch 12/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0987 - binary_accuracy: 0.9597 - auc_11: 0.9958 - val_loss: 0.5999 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8931\n",
            "Epoch 13/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0688 - binary_accuracy: 0.9732 - auc_11: 0.9989 - val_loss: 0.6002 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8931\n",
            "Epoch 14/40\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0932 - binary_accuracy: 0.9463 - auc_11: 0.9957 - val_loss: 0.5953 - val_binary_accuracy: 0.8158 - val_auc_11: 0.8958\n",
            "Epoch 15/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0534 - binary_accuracy: 0.9866 - auc_11: 0.9994 - val_loss: 0.5848 - val_binary_accuracy: 0.8158 - val_auc_11: 0.9000\n",
            "Epoch 16/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0310 - binary_accuracy: 0.9933 - auc_11: 1.0000 - val_loss: 0.5887 - val_binary_accuracy: 0.8158 - val_auc_11: 0.9056\n",
            "Epoch 17/40\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0336 - binary_accuracy: 1.0000 - auc_11: 1.0000 - val_loss: 0.5944 - val_binary_accuracy: 0.8421 - val_auc_11: 0.9014\n",
            "Epoch 18/40\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0320 - binary_accuracy: 0.9933 - auc_11: 1.0000 - val_loss: 0.6060 - val_binary_accuracy: 0.8421 - val_auc_11: 0.9014\n",
            "Epoch 19/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0267 - binary_accuracy: 0.9933 - auc_11: 1.0000 - val_loss: 0.6376 - val_binary_accuracy: 0.8421 - val_auc_11: 0.9042\n",
            "Epoch 20/40\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0472 - binary_accuracy: 0.9799 - auc_11: 0.9989 - val_loss: 0.6417 - val_binary_accuracy: 0.8421 - val_auc_11: 0.9083\n",
            "Epoch 21/40\n",
            "5/5 [==============================] - 1s 293ms/step - loss: 0.0603 - binary_accuracy: 0.9866 - auc_11: 0.9977 - val_loss: 0.6152 - val_binary_accuracy: 0.8684 - val_auc_11: 0.9111\n",
            "Epoch 22/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0235 - binary_accuracy: 0.9933 - auc_11: 0.9998 - val_loss: 0.6154 - val_binary_accuracy: 0.8947 - val_auc_11: 0.9097\n",
            "Epoch 23/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0242 - binary_accuracy: 1.0000 - auc_11: 1.0000 - val_loss: 0.6417 - val_binary_accuracy: 0.8947 - val_auc_11: 0.9097\n",
            "Epoch 24/40\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0316 - binary_accuracy: 0.9866 - auc_11: 0.9998 - val_loss: 0.6534 - val_binary_accuracy: 0.8947 - val_auc_11: 0.9000\n",
            "Epoch 25/40\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.0320 - binary_accuracy: 0.9866 - auc_11: 0.9998 - val_loss: 0.7447 - val_binary_accuracy: 0.8421 - val_auc_11: 0.9097\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7178 - binary_accuracy: 0.8085 - auc_11: 0.8736\n",
            "loss: 71.78%\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 4s 293ms/step - loss: 0.7304 - binary_accuracy: 0.5973 - auc_12: 0.6277 - val_loss: 0.7048 - val_binary_accuracy: 0.7632 - val_auc_12: 0.7875\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.3502 - binary_accuracy: 0.8121 - auc_12: 0.9396 - val_loss: 0.6021 - val_binary_accuracy: 0.7632 - val_auc_12: 0.8139\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.2319 - binary_accuracy: 0.8926 - auc_12: 0.9763 - val_loss: 0.6342 - val_binary_accuracy: 0.7632 - val_auc_12: 0.8111\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.1788 - binary_accuracy: 0.9329 - auc_12: 0.9849 - val_loss: 0.7189 - val_binary_accuracy: 0.7895 - val_auc_12: 0.8278\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.1758 - binary_accuracy: 0.9396 - auc_12: 0.9819 - val_loss: 0.7829 - val_binary_accuracy: 0.7632 - val_auc_12: 0.8278\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.1533 - binary_accuracy: 0.9530 - auc_12: 0.9868 - val_loss: 0.7710 - val_binary_accuracy: 0.7632 - val_auc_12: 0.8361\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.1417 - binary_accuracy: 0.9463 - auc_12: 0.9854 - val_loss: 0.7738 - val_binary_accuracy: 0.7632 - val_auc_12: 0.8375\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.1399 - binary_accuracy: 0.9530 - auc_12: 0.9872 - val_loss: 0.7904 - val_binary_accuracy: 0.7632 - val_auc_12: 0.8375\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.1526 - binary_accuracy: 0.9597 - auc_12: 0.9830 - val_loss: 0.7969 - val_binary_accuracy: 0.7632 - val_auc_12: 0.8361\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 0.1525 - binary_accuracy: 0.9664 - auc_12: 0.9782 - val_loss: 0.8103 - val_binary_accuracy: 0.7895 - val_auc_12: 0.8403\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.1417 - binary_accuracy: 0.9597 - auc_12: 0.9821 - val_loss: 0.7987 - val_binary_accuracy: 0.7895 - val_auc_12: 0.8375\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 7s 483ms/step - loss: 0.1041 - binary_accuracy: 0.9732 - auc_13: 0.9923 - val_loss: 0.7958 - val_binary_accuracy: 0.7895 - val_auc_13: 0.8417\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0828 - binary_accuracy: 0.9664 - auc_13: 0.9979 - val_loss: 0.7855 - val_binary_accuracy: 0.7895 - val_auc_13: 0.8625\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0743 - binary_accuracy: 0.9799 - auc_13: 0.9979 - val_loss: 0.8041 - val_binary_accuracy: 0.7632 - val_auc_13: 0.8458\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0723 - binary_accuracy: 0.9732 - auc_13: 0.9970 - val_loss: 0.7954 - val_binary_accuracy: 0.7895 - val_auc_13: 0.8681\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0847 - binary_accuracy: 0.9732 - auc_13: 0.9975 - val_loss: 0.7953 - val_binary_accuracy: 0.7895 - val_auc_13: 0.8653\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 1s 293ms/step - loss: 0.0365 - binary_accuracy: 0.9866 - auc_13: 0.9998 - val_loss: 0.8949 - val_binary_accuracy: 0.7895 - val_auc_13: 0.8556\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0379 - binary_accuracy: 0.9933 - auc_13: 1.0000 - val_loss: 0.8427 - val_binary_accuracy: 0.7895 - val_auc_13: 0.8639\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0392 - binary_accuracy: 0.9933 - auc_13: 0.9987 - val_loss: 0.8384 - val_binary_accuracy: 0.7895 - val_auc_13: 0.8778\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0308 - binary_accuracy: 0.9933 - auc_13: 1.0000 - val_loss: 0.8653 - val_binary_accuracy: 0.8158 - val_auc_13: 0.8667\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0295 - binary_accuracy: 0.9933 - auc_13: 0.9995 - val_loss: 0.9124 - val_binary_accuracy: 0.8158 - val_auc_13: 0.8653\n",
            "Epoch 11/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0251 - binary_accuracy: 0.9866 - auc_13: 1.0000 - val_loss: 0.8955 - val_binary_accuracy: 0.7895 - val_auc_13: 0.8667\n",
            "Epoch 12/40\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0085 - binary_accuracy: 1.0000 - auc_13: 1.0000 - val_loss: 0.8897 - val_binary_accuracy: 0.8158 - val_auc_13: 0.8750\n",
            "Epoch 13/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0188 - binary_accuracy: 1.0000 - auc_13: 1.0000 - val_loss: 0.9078 - val_binary_accuracy: 0.8158 - val_auc_13: 0.8764\n",
            "Epoch 14/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0120 - binary_accuracy: 1.0000 - auc_13: 1.0000 - val_loss: 0.9184 - val_binary_accuracy: 0.8421 - val_auc_13: 0.8764\n",
            "Epoch 15/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0117 - binary_accuracy: 1.0000 - auc_13: 1.0000 - val_loss: 0.9240 - val_binary_accuracy: 0.8421 - val_auc_13: 0.8778\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2764 - binary_accuracy: 0.9362 - auc_13: 0.9719\n",
            "loss: 27.64%\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 4s 311ms/step - loss: 0.5152 - binary_accuracy: 0.7315 - auc_14: 0.8100 - val_loss: 0.5108 - val_binary_accuracy: 0.8421 - val_auc_14: 0.8417\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.1990 - binary_accuracy: 0.9262 - auc_14: 0.9805 - val_loss: 0.5932 - val_binary_accuracy: 0.8421 - val_auc_14: 0.8542\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.1538 - binary_accuracy: 0.9463 - auc_14: 0.9897 - val_loss: 0.5862 - val_binary_accuracy: 0.8684 - val_auc_14: 0.8583\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.1111 - binary_accuracy: 0.9597 - auc_14: 0.9957 - val_loss: 0.6468 - val_binary_accuracy: 0.8947 - val_auc_14: 0.8653\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.0604 - binary_accuracy: 0.9933 - auc_14: 0.9991 - val_loss: 0.6788 - val_binary_accuracy: 0.8947 - val_auc_14: 0.8583\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0406 - binary_accuracy: 1.0000 - auc_14: 1.0000 - val_loss: 0.7202 - val_binary_accuracy: 0.8947 - val_auc_14: 0.8625\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0652 - binary_accuracy: 0.9664 - auc_14: 0.9981 - val_loss: 0.7555 - val_binary_accuracy: 0.8947 - val_auc_14: 0.8625\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 0.0476 - binary_accuracy: 0.9933 - auc_14: 0.9985 - val_loss: 0.7582 - val_binary_accuracy: 0.8947 - val_auc_14: 0.8625\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0405 - binary_accuracy: 0.9933 - auc_14: 0.9989 - val_loss: 0.7703 - val_binary_accuracy: 0.8947 - val_auc_14: 0.8625\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0551 - binary_accuracy: 0.9933 - auc_14: 0.9973 - val_loss: 0.7840 - val_binary_accuracy: 0.8684 - val_auc_14: 0.8625\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0266 - binary_accuracy: 0.9933 - auc_14: 1.0000 - val_loss: 0.8048 - val_binary_accuracy: 0.8684 - val_auc_14: 0.8625\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0371 - binary_accuracy: 0.9799 - auc_14: 0.9996 - val_loss: 0.8140 - val_binary_accuracy: 0.8684 - val_auc_14: 0.8625\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0436 - binary_accuracy: 0.9933 - auc_14: 0.9993 - val_loss: 0.8545 - val_binary_accuracy: 0.8684 - val_auc_14: 0.8708\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0386 - binary_accuracy: 0.9799 - auc_14: 0.9994 - val_loss: 0.8627 - val_binary_accuracy: 0.8684 - val_auc_14: 0.8708\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 7s 497ms/step - loss: 0.0280 - binary_accuracy: 0.9933 - auc_15: 1.0000 - val_loss: 0.9186 - val_binary_accuracy: 0.8684 - val_auc_15: 0.8625\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0318 - binary_accuracy: 0.9866 - auc_15: 0.9998 - val_loss: 1.0069 - val_binary_accuracy: 0.8684 - val_auc_15: 0.8847\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0225 - binary_accuracy: 1.0000 - auc_15: 1.0000 - val_loss: 1.0127 - val_binary_accuracy: 0.8421 - val_auc_15: 0.8417\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0347 - binary_accuracy: 0.9866 - auc_15: 0.9996 - val_loss: 0.9903 - val_binary_accuracy: 0.8684 - val_auc_15: 0.8792\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0277 - binary_accuracy: 0.9866 - auc_15: 0.9999 - val_loss: 0.9924 - val_binary_accuracy: 0.8684 - val_auc_15: 0.8625\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0324 - binary_accuracy: 0.9866 - auc_15: 1.0000 - val_loss: 1.0141 - val_binary_accuracy: 0.8684 - val_auc_15: 0.8556\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0856 - binary_accuracy: 0.9574 - auc_15: 0.9982\n",
            "loss: 8.56%\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 4s 294ms/step - loss: 0.8087 - binary_accuracy: 0.5436 - auc_16: 0.6512 - val_loss: 0.4252 - val_binary_accuracy: 0.8158 - val_auc_16: 0.8934\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.3448 - binary_accuracy: 0.8658 - auc_16: 0.9326 - val_loss: 0.3655 - val_binary_accuracy: 0.8421 - val_auc_16: 0.9238\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 0.1884 - binary_accuracy: 0.9463 - auc_16: 0.9853 - val_loss: 0.4106 - val_binary_accuracy: 0.8684 - val_auc_16: 0.9141\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.1040 - binary_accuracy: 0.9597 - auc_16: 0.9953 - val_loss: 0.4743 - val_binary_accuracy: 0.8421 - val_auc_16: 0.9141\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0590 - binary_accuracy: 0.9933 - auc_16: 0.9991 - val_loss: 0.5297 - val_binary_accuracy: 0.8421 - val_auc_16: 0.9072\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0350 - binary_accuracy: 0.9933 - auc_16: 1.0000 - val_loss: 0.5536 - val_binary_accuracy: 0.8421 - val_auc_16: 0.9030\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0487 - binary_accuracy: 0.9866 - auc_16: 0.9979 - val_loss: 0.5650 - val_binary_accuracy: 0.8684 - val_auc_16: 0.9114\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0473 - binary_accuracy: 0.9866 - auc_16: 0.9991 - val_loss: 0.5848 - val_binary_accuracy: 0.8684 - val_auc_16: 0.9141\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 0.0282 - binary_accuracy: 1.0000 - auc_16: 1.0000 - val_loss: 0.6055 - val_binary_accuracy: 0.8421 - val_auc_16: 0.9114\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0335 - binary_accuracy: 0.9933 - auc_16: 0.9996 - val_loss: 0.6149 - val_binary_accuracy: 0.8684 - val_auc_16: 0.9169\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0898 - binary_accuracy: 0.9799 - auc_16: 0.9894 - val_loss: 0.6287 - val_binary_accuracy: 0.8684 - val_auc_16: 0.9169\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0318 - binary_accuracy: 0.9866 - auc_16: 0.9998 - val_loss: 0.6751 - val_binary_accuracy: 0.8421 - val_auc_16: 0.9017\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 7s 490ms/step - loss: 0.0588 - binary_accuracy: 0.9799 - auc_17: 0.9985 - val_loss: 0.5931 - val_binary_accuracy: 0.8684 - val_auc_17: 0.9224\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 292ms/step - loss: 0.0304 - binary_accuracy: 0.9933 - auc_17: 0.9998 - val_loss: 0.7027 - val_binary_accuracy: 0.8421 - val_auc_17: 0.8795\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0196 - binary_accuracy: 1.0000 - auc_17: 1.0000 - val_loss: 0.6324 - val_binary_accuracy: 0.8684 - val_auc_17: 0.9280\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0206 - binary_accuracy: 0.9933 - auc_17: 1.0000 - val_loss: 0.6500 - val_binary_accuracy: 0.8684 - val_auc_17: 0.9307\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0113 - binary_accuracy: 1.0000 - auc_17: 1.0000 - val_loss: 0.7551 - val_binary_accuracy: 0.8684 - val_auc_17: 0.9127\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0162 - binary_accuracy: 0.9933 - auc_17: 1.0000 - val_loss: 0.7805 - val_binary_accuracy: 0.8684 - val_auc_17: 0.9155\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0291 - binary_accuracy: 0.9866 - auc_17: 0.9996 - val_loss: 0.7123 - val_binary_accuracy: 0.8684 - val_auc_17: 0.9280\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 1s 293ms/step - loss: 0.0059 - binary_accuracy: 1.0000 - auc_17: 1.0000 - val_loss: 0.7107 - val_binary_accuracy: 0.8684 - val_auc_17: 0.9294\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0106 - binary_accuracy: 1.0000 - auc_17: 1.0000 - val_loss: 0.7439 - val_binary_accuracy: 0.8684 - val_auc_17: 0.9280\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0142 - binary_accuracy: 0.9933 - auc_17: 1.0000 - val_loss: 0.7467 - val_binary_accuracy: 0.8684 - val_auc_17: 0.9294\n",
            "Epoch 11/40\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0084 - binary_accuracy: 1.0000 - auc_17: 1.0000 - val_loss: 0.7069 - val_binary_accuracy: 0.8947 - val_auc_17: 0.9335\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3428 - binary_accuracy: 0.9362 - auc_17: 0.9731\n",
            "loss: 34.28%\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 4s 288ms/step - loss: 0.5972 - binary_accuracy: 0.7133 - auc_18: 0.7887 - val_loss: 0.5471 - val_binary_accuracy: 0.8947 - val_auc_18: 0.8393\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.1722 - binary_accuracy: 0.9400 - auc_18: 0.9882 - val_loss: 0.6717 - val_binary_accuracy: 0.8947 - val_auc_18: 0.8643\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 0.0975 - binary_accuracy: 0.9667 - auc_18: 0.9957 - val_loss: 0.7335 - val_binary_accuracy: 0.8684 - val_auc_18: 0.8684\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 0.0435 - binary_accuracy: 0.9867 - auc_18: 0.9998 - val_loss: 0.8535 - val_binary_accuracy: 0.8947 - val_auc_18: 0.8850\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0225 - binary_accuracy: 1.0000 - auc_18: 1.0000 - val_loss: 0.9101 - val_binary_accuracy: 0.8947 - val_auc_18: 0.8864\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0187 - binary_accuracy: 1.0000 - auc_18: 1.0000 - val_loss: 0.9449 - val_binary_accuracy: 0.8684 - val_auc_18: 0.8906\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 0.0196 - binary_accuracy: 0.9933 - auc_18: 1.0000 - val_loss: 0.9673 - val_binary_accuracy: 0.8684 - val_auc_18: 0.8864\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0246 - binary_accuracy: 0.9933 - auc_18: 1.0000 - val_loss: 0.9791 - val_binary_accuracy: 0.8684 - val_auc_18: 0.8823\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 0.0138 - binary_accuracy: 0.9933 - auc_18: 1.0000 - val_loss: 0.9959 - val_binary_accuracy: 0.8421 - val_auc_18: 0.8823\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 0.0256 - binary_accuracy: 0.9867 - auc_18: 0.9998 - val_loss: 1.0157 - val_binary_accuracy: 0.8421 - val_auc_18: 0.8795\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.0175 - binary_accuracy: 1.0000 - auc_18: 1.0000 - val_loss: 1.0342 - val_binary_accuracy: 0.8684 - val_auc_18: 0.8850\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.0183 - binary_accuracy: 1.0000 - auc_18: 1.0000 - val_loss: 1.0558 - val_binary_accuracy: 0.8684 - val_auc_18: 0.8920\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 7s 523ms/step - loss: 0.0104 - binary_accuracy: 1.0000 - auc_19: 1.0000 - val_loss: 1.1243 - val_binary_accuracy: 0.8421 - val_auc_19: 0.8781\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0212 - binary_accuracy: 0.9933 - auc_19: 1.0000 - val_loss: 1.1758 - val_binary_accuracy: 0.8684 - val_auc_19: 0.8823\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0321 - binary_accuracy: 0.9800 - auc_19: 0.9996 - val_loss: 1.2032 - val_binary_accuracy: 0.8421 - val_auc_19: 0.8698\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0052 - binary_accuracy: 1.0000 - auc_19: 1.0000 - val_loss: 1.2090 - val_binary_accuracy: 0.8421 - val_auc_19: 0.8601\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0050 - binary_accuracy: 1.0000 - auc_19: 1.0000 - val_loss: 1.1911 - val_binary_accuracy: 0.8421 - val_auc_19: 0.8712\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0097 - binary_accuracy: 1.0000 - auc_19: 1.0000 - val_loss: 1.2085 - val_binary_accuracy: 0.8421 - val_auc_19: 0.8837\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0090 - binary_accuracy: 1.0000 - auc_19: 1.0000 - val_loss: 1.2048 - val_binary_accuracy: 0.8421 - val_auc_19: 0.8795\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.0073 - binary_accuracy: 1.0000 - auc_19: 1.0000 - val_loss: 1.2108 - val_binary_accuracy: 0.8421 - val_auc_19: 0.8795\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0179 - binary_accuracy: 1.0000 - auc_19: 1.0000\n",
            "loss: 1.79%\n",
            "92.77% (+/- 6.40%)\n",
            "0.96% (+/- 0.05%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNza1IFFltp0"
      },
      "source": [
        "raw_preds_L = flatten(flatten(raw_preds))\n",
        "gts_L = flatten(gts)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctltpoZ7u_Ya",
        "outputId": "29b028ce-fedf-4ac7-f2e3-a89512159571"
      },
      "source": [
        "accscores = []\n",
        "aucscores = []\n",
        "raw_preds = []\n",
        "gts = []\n",
        "\n",
        "for kfold, (train, test) in enumerate(KFold(n_splits=5, shuffle=True).split(x_L, y_L)):\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  base_model_ap.trainable = False\n",
        "  base_model_ap._name=\"AP-View-Model\"\n",
        "\n",
        "  inputs_ap = keras.Input(shape=(150, 150, 3) ,name= \"ap_input\")\n",
        "  \n",
        "  augmented_ap = data_augmentation_ap(inputs_ap)  \n",
        "\n",
        "  norm_layer_ap = keras.layers.experimental.preprocessing.Normalization()\n",
        "  mean = np.array([127.5] * 3)\n",
        "  var = mean ** 2\n",
        "  augmented_ap = norm_layer_ap(augmented_ap)\n",
        "  norm_layer_ap.set_weights([mean, var])\n",
        "\n",
        "  augmented_ap = base_model_ap(augmented_ap, training=False)\n",
        "\n",
        "  augmented_ap = keras.layers.GlobalAveragePooling2D()(augmented_ap)\n",
        "  augmented_ap = keras.layers.Dropout(0.2)(augmented_ap)  # Regularize with dropout\n",
        "\n",
        "\n",
        "  base_model_L.trainable = False\n",
        "  base_model_L._name=\"L-Model\"\n",
        "\n",
        "  inputs_L = keras.Input(shape=(150, 150, 3), name=\"L_input\")\n",
        "  augmented_L = data_augmentation_L(inputs_L)  \n",
        "\n",
        "  norm_layer_L = keras.layers.experimental.preprocessing.Normalization()\n",
        "  mean = np.array([127.5] * 3)\n",
        "  var = mean ** 2\n",
        "  augmented_L = norm_layer_L(augmented_L)\n",
        "  norm_layer_L.set_weights([mean, var])\n",
        "  augmented_L = base_model_L(augmented_L, training=False)\n",
        "\n",
        "\n",
        "  augmented_L = keras.layers.GlobalAveragePooling2D()(augmented_L)\n",
        "  augmented_L = keras.layers.Dropout(0.2)(augmented_L)  # Regularize with dropout\n",
        "\n",
        "  cat = layers.concatenate([augmented_L, augmented_ap])\n",
        "  cat = layers.Flatten()(cat)\n",
        "  dense = layers.Dense(512)(cat)\n",
        "  dense = layers.LeakyReLU(alpha=0.1)(dense)\n",
        "  dense = layers.Dropout(0.5)(dense)\n",
        "  outputs = layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "  model = keras.Model(inputs=[inputs_ap, inputs_L], outputs=outputs,)\n",
        "\n",
        "  #-----------Model is now defined, moving on to training---------\n",
        "\n",
        "  callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.AUC()],\n",
        "  )\n",
        "\n",
        "  epochs = 200\n",
        "\n",
        "  #First fit with frozen weights\n",
        "  model.fit(x=[x_ap[train], x_L[train]],y=y_ap[train] , callbacks=[callback], epochs=epochs, validation_split=0.2)\n",
        "\n",
        "  base_model_L.trainable = True\n",
        "  base_model_ap.trainable = True\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "      loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.AUC()],\n",
        "  )\n",
        "\n",
        "  epochs = 40\n",
        "\n",
        "  #Second fit\n",
        "  model.fit(x=[x_ap[train], x_L[train]],y=y_ap[train] , callbacks=[callback], epochs=epochs, validation_split=0.2)\n",
        "\n",
        "  #Evaluate\n",
        "  predictions = model.predict([x_ap[test], x_L[test]])\n",
        "  raw_preds.append(predictions)\n",
        "  gts.append(y_L[test])\n",
        "  scores = model.evaluate(x=[x_ap[test], x_L[test]], y=y_L[test])\n",
        "  \n",
        "\n",
        "  print(\"%s: %.2f%%\" % (model_L.metrics_names[0], scores[0]*100))\n",
        "  accscores.append(scores[1] * 100)\n",
        "  aucscores.append(scores[2])\n",
        " \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accscores), np.std(accscores)))\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(aucscores), np.std(aucscores)))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:5017: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`binary_crossentropy` received `from_logits=True`, but the `output`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 533ms/step - loss: 0.7651 - binary_accuracy: 0.8054 - auc: 0.9010 - val_loss: 3.6515 - val_binary_accuracy: 0.8947 - val_auc: 0.9217\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.0224 - binary_accuracy: 0.9933 - auc: 1.0000 - val_loss: 4.6877 - val_binary_accuracy: 0.8947 - val_auc: 0.9188\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0180 - binary_accuracy: 0.9933 - auc: 1.0000 - val_loss: 6.6989 - val_binary_accuracy: 0.8684 - val_auc: 0.8986\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 3.6132e-11 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.7679 - val_binary_accuracy: 0.8421 - val_auc: 0.8580\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 3.1013e-12 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 10.0617 - val_binary_accuracy: 0.8421 - val_auc: 0.8580\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 1.2245e-15 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 10.8747 - val_binary_accuracy: 0.8421 - val_auc: 0.8580\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 1.8185e-18 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 11.3878 - val_binary_accuracy: 0.8421 - val_auc: 0.8580\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 8.1768e-12 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 11.7080 - val_binary_accuracy: 0.8421 - val_auc: 0.8580\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 1s 190ms/step - loss: 8.5334e-13 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 11.9072 - val_binary_accuracy: 0.8421 - val_auc: 0.8580\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 1.5744e-17 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 12.0307 - val_binary_accuracy: 0.8421 - val_auc: 0.8580\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 13s 873ms/step - loss: 8.4062e-10 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 12.0260 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8580\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 3s 505ms/step - loss: 1.2362e-10 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 12.0089 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8580\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 3s 510ms/step - loss: 2.7554e-12 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 11.9993 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8580\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 3s 509ms/step - loss: 1.0939e-16 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 11.9936 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8580\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 3s 511ms/step - loss: 3.7189e-07 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 10.8252 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8580\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 3s 511ms/step - loss: 1.3763e-11 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 9.7999 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8580\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 3s 509ms/step - loss: 1.4067e-21 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 9.1418 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8783\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 3s 511ms/step - loss: 5.0703e-16 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 8.7595 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8986\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 4.2300e-18 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 8.5900 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8986\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - 3s 553ms/step - loss: 3.6353e-08 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 8.5963 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8986\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 1.3357 - binary_accuracy: 0.9787 - auc_1: 0.9808\n",
            "loss: 133.57%\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 7s 562ms/step - loss: 5.0075 - binary_accuracy: 0.7315 - auc: 0.7529 - val_loss: 8.0021 - val_binary_accuracy: 0.7105 - val_auc: 0.7895\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.6280 - binary_accuracy: 0.8993 - auc: 0.9462 - val_loss: 4.6211 - val_binary_accuracy: 0.7895 - val_auc: 0.7895\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 1.2618e-09 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.4673 - val_binary_accuracy: 0.8158 - val_auc: 0.8629\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 3.0613e-05 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3859 - val_binary_accuracy: 0.8947 - val_auc: 0.8920\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 0.0352 - binary_accuracy: 0.9933 - auc: 1.0000 - val_loss: 3.5003 - val_binary_accuracy: 0.8947 - val_auc: 0.8920\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.0587 - binary_accuracy: 0.9933 - auc: 0.9940 - val_loss: 3.6180 - val_binary_accuracy: 0.8947 - val_auc: 0.8920\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 14s 925ms/step - loss: 3.9656e-05 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 4.3751 - val_binary_accuracy: 0.8158 - val_auc_1: 0.8158\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 3s 527ms/step - loss: 3.0475e-08 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 7.0430 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8587\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 3s 527ms/step - loss: 0.0375 - binary_accuracy: 0.9866 - auc_1: 1.0000 - val_loss: 4.6307 - val_binary_accuracy: 0.8158 - val_auc_1: 0.8393\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 3s 526ms/step - loss: 5.9222e-09 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 3.6268 - val_binary_accuracy: 0.9211 - val_auc_1: 0.9183\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 3s 535ms/step - loss: 0.0373 - binary_accuracy: 0.9933 - auc_1: 0.9940 - val_loss: 3.6616 - val_binary_accuracy: 0.8947 - val_auc_1: 0.9127\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 3s 516ms/step - loss: 1.3956e-11 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 4.4212 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8393\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 3s 524ms/step - loss: 1.9708e-06 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 4.9768 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8393\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 3s 522ms/step - loss: 1.6012e-11 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 5.3436 - val_binary_accuracy: 0.8158 - val_auc_1: 0.8587\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 3s 534ms/step - loss: 8.8875e-11 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 5.5858 - val_binary_accuracy: 0.8158 - val_auc_1: 0.8587\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 2.7521 - binary_accuracy: 0.9787 - auc_1: 0.9762\n",
            "loss: 275.21%\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 8s 792ms/step - loss: 0.2304 - binary_accuracy: 0.9262 - auc: 0.9829 - val_loss: 6.0579 - val_binary_accuracy: 0.7895 - val_auc: 0.8500\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 2.5345e-06 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.6047 - val_binary_accuracy: 0.8684 - val_auc: 0.8889\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.0809 - binary_accuracy: 0.9933 - auc: 0.9941 - val_loss: 9.5877 - val_binary_accuracy: 0.7895 - val_auc: 0.8333\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 4.9129e-15 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 13.0921 - val_binary_accuracy: 0.8158 - val_auc: 0.8083\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 4.1783e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 14.8515 - val_binary_accuracy: 0.8158 - val_auc: 0.8250\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 2.3146e-07 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 15.6593 - val_binary_accuracy: 0.8158 - val_auc: 0.8250\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 1.9398e-07 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 16.1620 - val_binary_accuracy: 0.8158 - val_auc: 0.8250\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 13s 880ms/step - loss: 9.7580e-08 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 15.9352 - val_binary_accuracy: 0.8158 - val_auc_1: 0.8250\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 3s 511ms/step - loss: 1.5518e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 10.9591 - val_binary_accuracy: 0.7895 - val_auc_1: 0.8083\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 3s 514ms/step - loss: 7.6024e-07 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 9.5542 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8639\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 3s 514ms/step - loss: 4.5647e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 10.5957 - val_binary_accuracy: 0.7895 - val_auc_1: 0.8083\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 7.6494e-07 - binary_accuracy: 1.0000 - auc_1: 1.0000\n",
            "loss: 0.00%\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 8s 538ms/step - loss: 4.3226 - binary_accuracy: 0.7718 - auc: 0.7884 - val_loss: 3.6040 - val_binary_accuracy: 0.8421 - val_auc: 0.8583\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.1755 - binary_accuracy: 0.9664 - auc: 0.9882 - val_loss: 5.2059 - val_binary_accuracy: 0.8421 - val_auc: 0.8389\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 0.0027 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8486 - val_binary_accuracy: 0.8158 - val_auc: 0.8583\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.0441 - binary_accuracy: 0.9866 - auc: 1.0000 - val_loss: 6.8546 - val_binary_accuracy: 0.8684 - val_auc: 0.8667\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 2.3204e-09 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 7.6328 - val_binary_accuracy: 0.8421 - val_auc: 0.8639\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 3.1900e-12 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.2756 - val_binary_accuracy: 0.8421 - val_auc: 0.8389\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 4.0566e-14 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.6744 - val_binary_accuracy: 0.8421 - val_auc: 0.8389\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 4.9776e-14 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.9227 - val_binary_accuracy: 0.8421 - val_auc: 0.8389\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 7.9948e-11 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 9.0787 - val_binary_accuracy: 0.8421 - val_auc: 0.8361\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 1.2025e-10 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 9.1764 - val_binary_accuracy: 0.8421 - val_auc: 0.8361\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 12s 937ms/step - loss: 4.3174e-16 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 9.1764 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8361\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 3s 515ms/step - loss: 1.9968e-06 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 8.5653 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8639\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 3s 517ms/step - loss: 1.5853e-15 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 8.2827 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8667\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 3s 518ms/step - loss: 9.5269e-06 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 8.3327 - val_binary_accuracy: 0.8684 - val_auc_1: 0.8639\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.1784 - binary_accuracy: 0.9574 - auc_1: 0.9783\n",
            "loss: 17.84%\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - 8s 552ms/step - loss: 8.9764 - binary_accuracy: 0.6133 - auc: 0.6345 - val_loss: 1.7309 - val_binary_accuracy: 0.9474 - val_auc: 0.9444\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 0.5469 - binary_accuracy: 0.9200 - auc: 0.9573 - val_loss: 3.4498 - val_binary_accuracy: 0.8421 - val_auc: 0.8292\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.2804 - binary_accuracy: 0.9533 - auc: 0.9756 - val_loss: 2.7019 - val_binary_accuracy: 0.9474 - val_auc: 0.9472\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 9.3825e-06 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3727 - val_binary_accuracy: 0.8684 - val_auc: 0.8944\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 1s 191ms/step - loss: 2.2584e-11 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.1066 - val_binary_accuracy: 0.8684 - val_auc: 0.8708\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 6.9315e-12 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.5852 - val_binary_accuracy: 0.8421 - val_auc: 0.8708\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 7.6417e-09 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.8974 - val_binary_accuracy: 0.8421 - val_auc: 0.8708\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 1.8456e-09 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.0901 - val_binary_accuracy: 0.8421 - val_auc: 0.8708\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 1s 192ms/step - loss: 1.0179e-04 - binary_accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2079 - val_binary_accuracy: 0.8421 - val_auc: 0.8917\n",
            "Epoch 1/40\n",
            "5/5 [==============================] - 12s 924ms/step - loss: 9.8263e-09 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 5.1963 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8917\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 3s 523ms/step - loss: 3.6290e-07 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 4.8782 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8708\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 3s 525ms/step - loss: 2.5614e-10 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 4.6803 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8708\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 3s 534ms/step - loss: 4.6181e-12 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 4.5586 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8708\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 8.1631e-10 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 4.4825 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8708\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 4.5374e-12 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 4.4343 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8708\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 3s 582ms/step - loss: 0.0320 - binary_accuracy: 0.9933 - auc_1: 0.9998 - val_loss: 4.2140 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8708\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 3s 531ms/step - loss: 2.1754e-08 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 6.8690 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8500\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 3s 530ms/step - loss: 5.1525e-04 - binary_accuracy: 1.0000 - auc_1: 1.0000 - val_loss: 8.1224 - val_binary_accuracy: 0.8421 - val_auc_1: 0.8500\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 3.6692 - binary_accuracy: 0.9565 - auc_1: 0.9412\n",
            "loss: 366.92%\n",
            "97.43% (+/- 1.61%)\n",
            "0.98% (+/- 0.02%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx00V4TdyM_1"
      },
      "source": [
        "raw_preds_combined = flatten(flatten(raw_preds))\n",
        "gts_combined = flatten(gts)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYPbQZemznUI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}